# LLM Daily Brief — 2026-01-30

- 生成时间：2026-01-30 10:26 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 官方 / 厂商 · 国外

- [Scaling content review operations with multi-agent workflow](https://aws.amazon.com/blogs/machine-learning/scaling-content-review-operations-with-multi-agent-workflow/) — AWS Machine Learning · Blog · 2026-01-30 07:32
- [Some users are experiencing delays in purchasing additional API credits](https://status.claude.com/incidents/29wh90pcv3r1) — Anthropic · Status · 2026-01-30 04:39
- [Mercedes-Benz Unveils New S-Class Built on NVIDIA DRIVE AV, Which Enables an L4-Ready Architecture](https://blogs.nvidia.com/blog/mercedes-benz-l4-s-class-drive-av-platform/) — NVIDIA Technical Blog · 2026-01-30 02:00
- [Into the Omniverse: Physical AI Open Models and Frameworks Advance Robots and Autonomous Systems](https://blogs.nvidia.com/blog/physical-ai-open-models-robot-autonomous-systems-omniverse/) — NVIDIA Technical Blog · 2026-01-30 01:00
- [GeForce NOW Brings GeForce RTX Gaming to Linux PCs](https://blogs.nvidia.com/blog/geforce-now-thursday-linux/) — NVIDIA Technical Blog · 2026-01-29 22:00


## 中文媒体

- [派早报：小米发布 REDMI Turbo 5 系列手机等](https://sspai.com/post/105895) — 少数派 · 2026-01-30 08:35


## 研究机构 / 开源社区

- [Introducing NVIDIA Cosmos Policy for Advanced Robot Control](https://huggingface.co/blog/nvidia/cosmos-policy-for-robot-control) — Hugging Face Blog · 2026-01-30 01:03


## 论文 · arXiv

- [EWSJF: An Adaptive Scheduler with Hybrid Partitioning for Mixed-Workload LLM Inference](https://arxiv.org/abs/2601.21758v1) — arXiv · LLM core · 2026-01-29 22:14
- [Language-based Trial and Error Falls Behind in the Era of Experience](https://arxiv.org/abs/2601.21754v1) — arXiv · LLM core · 2026-01-29 22:08
- [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744v1) — arXiv · LLM core · 2026-01-29 22:01
- [Epistemic Context Learning: Building Trust the Right Way in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2601.21742v1) — arXiv · LLM core · 2026-01-29 21:59
- [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733v1) — arXiv · LLM core · 2026-01-29 21:53
- [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725v1) — arXiv · LLM core · 2026-01-29 21:48
- [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722v1) — arXiv · LLM core · 2026-01-29 21:46
- [When does predictive inverse dynamics outperform behavior cloning?](https://arxiv.org/abs/2601.21718v1) — arXiv · MoE & Reasoning · 2026-01-29 21:43
- [DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning](https://arxiv.org/abs/2601.21716v1) — arXiv · MoE & Reasoning · 2026-01-29 21:43
- [E-mem: Multi-agent based Episodic Context Reconstruction for LLM Agent Memory](https://arxiv.org/abs/2601.21714v1) — arXiv · LLM core · 2026-01-29 21:42
- [Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations](https://arxiv.org/abs/2601.21713v1) — arXiv · MoE & Reasoning · 2026-01-29 21:41
- [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711v1) — arXiv · LLM core · 2026-01-29 21:40
- [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709v1) — arXiv · LLM core · 2026-01-29 21:40
- [Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning](https://arxiv.org/abs/2601.21700v1) — arXiv · MoE & Reasoning · 2026-01-29 21:31
- [Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents](https://arxiv.org/abs/2601.21699v1) — arXiv · MoE & Reasoning · 2026-01-29 21:31

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
# LLM Daily Brief — 2025-08-28

- 生成时间：2025-08-28 20:43 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 官方 / 厂商 · 国外

- [Elevated errors on Claude Opus 4.1](https://status.anthropic.com/incidents/fd8pwt3p6c4q) — Anthropic · Status · 2025-08-28 20:29
- [Elevated errors on Claude Opus 4.1](https://status.anthropic.com/incidents/89mlxfnc19xm) — Anthropic · Status · 2025-08-28 19:20


## 中文媒体

- [一帮人All in AI，让搞体育的先赚到钱了](https://www.qbitai.com/2025/08/327097.html) — 量子位 · 2025-08-28 19:37
- [谷歌又赢了，nano banana「被迫」改名后，网友搞出7种神仙玩法](https://www.jiqizhixin.com/articles/2025-08-28-17) — 机器之心 · 2025-08-28 19:02
- [全新岚图知音正式上市，20.29万元起](https://www.qbitai.com/2025/08/327089.html) — 量子位 · 2025-08-28 18:56
- [杜克大学、Zoom推出LiveMCP‑101：GPT‑5表现最佳但未破60%，闭源模型Token效率对数规律引关注](https://www.jiqizhixin.com/articles/2025-08-28-16) — 机器之心 · 2025-08-28 18:53
- [来和数字员工「AI吴彦祖」聊聊天，百度智能云重磅升级百舸5.0、千帆4.0](https://www.jiqizhixin.com/articles/2025-08-28-15) — 机器之心 · 2025-08-28 18:22
- [元石科技正式发布问小白5，性能直追GPT-5](https://www.jiqizhixin.com/articles/2025-08-28-13) — 机器之心 · 2025-08-28 17:54
- [刚刚更新，全球AI百强：中国五款产品进前20，ChatGPT背腹受敌，氛围编程成黑马](https://www.jiqizhixin.com/articles/2025-08-28-12) — 机器之心 · 2025-08-28 17:49
- [33.5万，「车位到车位」上车坦克500，硬派越野标杆也可家用](https://www.qbitai.com/2025/08/327076.html) — 量子位 · 2025-08-28 17:37
- [新玩意 219｜少数派的编辑们最近买了啥？](https://sspai.com/post/102159) — 少数派 · 2025-08-28 17:30
- [奇点灵智获数千万元天使轮融资，打造儿童AI英语伴学新起点](https://www.qbitai.com/2025/08/327067.html) — 量子位 · 2025-08-28 17:24
- [啊？猫猫也会老年痴呆](https://www.qbitai.com/2025/08/327024.html) — 量子位 · 2025-08-28 17:14
- [共创栏目预览 | 久坐一族如何缓解腰背酸痛](https://sspai.com/post/102102) — 少数派 · 2025-08-28 15:01
- [老车主、新视角：小鹏 MONA M03 Max 随行体验](https://sspai.com/post/102094) — 少数派 · 2025-08-28 10:54


## 论文 · arXiv

- [Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy   Retriever Poisoning](http://arxiv.org/abs/2508.20083v1) — arXiv · LLM core · 2025-08-28 01:49
- [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with   Cognitive-Inspired Analysis](http://arxiv.org/abs/2508.20068v1) — arXiv · LLM core · 2025-08-28 01:22
- [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to   Enhance LLM Safety Guardrail to Potential Attacks](http://arxiv.org/abs/2508.20038v1) — arXiv · LLM core · 2025-08-28 00:44
- [Pruning Strategies for Backdoor Defense in LLMs](http://arxiv.org/abs/2508.20032v1) — arXiv · LLM core · 2025-08-28 00:34
- [Large Language Models (LLMs) for Electronic Design Automation (EDA)](http://arxiv.org/abs/2508.20030v1) — arXiv · LLM core · 2025-08-28 00:33
- [Using item recommendations and LLMs in marketing email titles](http://arxiv.org/abs/2508.20024v1) — arXiv · LLM core · 2025-08-28 00:31
- [FairLoop: Software Support for Human-Centric Fairness in Predictive   Business Process Monitoring](http://arxiv.org/abs/2508.20021v1) — arXiv · MoE & Reasoning · 2025-08-28 00:30
- [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective   Intelligence](http://arxiv.org/abs/2508.20019v1) — arXiv · LLM core · 2025-08-28 00:27
- [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in   Mobile GUI Control](http://arxiv.org/abs/2508.20018v1) — arXiv · MoE & Reasoning · 2025-08-28 00:27
- [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for   Emergent Misalignment](http://arxiv.org/abs/2508.20015v1) — arXiv · LLM core · 2025-08-28 00:19
- [Linear-Time Demonstration Selection for In-Context Learning via Gradient   Estimation](http://arxiv.org/abs/2508.19999v1) — arXiv · MoE & Reasoning · 2025-08-27 23:59
- [MathBuddy: A Multimodal System for Affective Math Tutoring](http://arxiv.org/abs/2508.19993v1) — arXiv · LLM core · 2025-08-27 23:50
- [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical   Reasoning in Real-World Scenarios](http://arxiv.org/abs/2508.19988v1) — arXiv · LLM core · 2025-08-27 23:47
- [Evaluating Language Model Reasoning about Confidential Information](http://arxiv.org/abs/2508.19980v1) — arXiv · MoE & Reasoning · 2025-08-27 23:39
- [Flocking Behavior: An Innovative Inspiration for the Optimization of   Production Plants](http://arxiv.org/abs/2508.19963v1) — arXiv · MoE & Reasoning · 2025-08-27 23:17
- [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA   Attuned to Diverse Visual Contexts](http://arxiv.org/abs/2508.19944v1) — arXiv · MoE & Reasoning · 2025-08-27 23:01

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
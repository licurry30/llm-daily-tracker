# LLM Daily Brief — 2025-09-11

- 生成时间：2025-09-11 20:42 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [19.79万起！智己LS6换代登场，纯电续航450km，卷出同级新高度](https://www.qbitai.com/2025/09/330613.html) — 量子位 · 2025-09-11 18:41
- [开源即登顶！文心思考模型ERNIE-4.5-21B-A3B-Thinking登顶HuggingFace全球模型趋势榜](https://www.qbitai.com/2025/09/330625.html) — 量子位 · 2025-09-11 18:04
- [腾讯会议打通腾讯元宝，“AI托管”当你的听会助手](https://www.qbitai.com/2025/09/330614.html) — 量子位 · 2025-09-11 17:48
- [也许是最适合普通人的「弹唱」入门设备：Musspark AI 随弹吉他 S1 mini 体验](https://sspai.com/post/102420) — 少数派 · 2025-09-11 17:30
- [又被李斌融到钱了：到账70亿](https://www.qbitai.com/2025/09/330582.html) — 量子位 · 2025-09-11 17:19
- [继首创“AI打赏”服务之后，支付宝再推国内首个“AI付”](https://www.jiqizhixin.com/articles/2025-09-11-12) — 机器之心 · 2025-09-11 16:54
- [蚂蚁百宝箱新品Tbox超级智能体亮相外滩大会，5分钟即可完成专业教学素材](https://www.jiqizhixin.com/articles/2025-09-11-11) — 机器之心 · 2025-09-11 16:50
- [2025人工智能年度评选启动！3大维度5类奖项，正在寻找AI+时代领航者](https://www.qbitai.com/2025/09/330518.html) — 量子位 · 2025-09-11 16:32
- [量子宇宙模拟竞赛开启：量子计算机可以模拟并阐明复杂物理现象](https://www.jiqizhixin.com/articles/2025-09-11-10) — 机器之心 · 2025-09-11 15:57
- [3000亿美元OpenAI大单，让世界首富位置换人了](https://www.jiqizhixin.com/articles/2025-09-11-9) — 机器之心 · 2025-09-11 15:41
- [攻克大模型「表格盲区」！ST-Raptor框架发布，实现复杂半结构化表格的精准理解与信息抽取](https://www.jiqizhixin.com/articles/2025-09-11-8) — 机器之心 · 2025-09-11 15:38
- [iPhone 17 系列发布会上没说的那些事](https://sspai.com/post/102432) — 少数派 · 2025-09-11 15:00
- [地表最强补剂？你可能需要这篇维生素 D 的「说明书」](https://sspai.com/post/102388) — 少数派 · 2025-09-11 11:30


## 研究机构 / 开源社区

- [Tricks from OpenAI gpt-oss YOU 🫵 can use with transformers](https://huggingface.co/blog/faster-transformers) — Hugging Face Blog · 2025-09-11 08:00


## 论文 · arXiv

- [A Survey of Reinforcement Learning for Large Reasoning Models](http://arxiv.org/abs/2509.08827v1) — arXiv · LLM core · 2025-09-11 01:59
- [Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs   for Text Annotation](http://arxiv.org/abs/2509.08825v1) — arXiv · LLM core · 2025-09-11 01:58
- [Building High-Quality Datasets for Portuguese LLMs: From Common Crawl   Snapshots to Industrial-Grade Corpora](http://arxiv.org/abs/2509.08824v1) — arXiv · LLM core · 2025-09-11 01:58
- [Merge-of-Thought Distillation](http://arxiv.org/abs/2509.08814v1) — arXiv · MoE & Reasoning · 2025-09-11 01:46
- [Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation   Through Unsupervised Consistency Signals](http://arxiv.org/abs/2509.08809v1) — arXiv · LLM core · 2025-09-11 01:42
- [Scaling Truth: The Confidence Paradox in AI Fact-Checking](http://arxiv.org/abs/2509.08803v1) — arXiv · LLM core · 2025-09-11 01:36
- [Narrative-Guided Reinforcement Learning: A Platform for Studying   Language Model Influence on Decision Making](http://arxiv.org/abs/2509.08785v1) — arXiv · MoE & Reasoning · 2025-09-11 01:14
- [Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles](http://arxiv.org/abs/2509.08777v1) — arXiv · LLM core · 2025-09-11 01:06
- [AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making   through Multi-Turn Reinforcement Learning](http://arxiv.org/abs/2509.08755v1) — arXiv · LLM core · 2025-09-11 00:46
- [FinZero: Launching Multi-modal Financial Time Series Forecast with Large   Reasoning Model](http://arxiv.org/abs/2509.08742v1) — arXiv · MoE & Reasoning · 2025-09-11 00:32
- [ChemBOMAS: Accelerated BO in Chemistry with LLM-Enhanced Multi-Agent   System](http://arxiv.org/abs/2509.08736v1) — arXiv · LLM core · 2025-09-11 00:24
- [X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to   Single-turn Jailbreak Templates](http://arxiv.org/abs/2509.08729v1) — arXiv · LLM core · 2025-09-11 00:17
- [Sharing is Caring: Efficient LM Post-Training with Collective RL   Experience Sharing](http://arxiv.org/abs/2509.08721v1) — arXiv · MoE & Reasoning · 2025-09-11 00:14
- [One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human   Biases](http://arxiv.org/abs/2509.08705v1) — arXiv · MoE & Reasoning · 2025-09-10 23:55
- [Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute   Implementations](http://arxiv.org/abs/2509.08646v1) — arXiv · LLM core · 2025-09-10 22:41
- [Memorization in Large Language Models in Medicine: Prevalence,   Characteristics, and Implications](http://arxiv.org/abs/2509.08604v1) — arXiv · MoE & Reasoning · 2025-09-10 22:02

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
# LLM Daily Brief — 2025-10-01

- 生成时间：2025-10-01 20:47 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [字节Seed发布PXDesign：蛋白设计效率提升十倍，进入实用新阶段](https://www.qbitai.com/2025/10/339061.html) — 量子位 · 2025-10-01 18:54
- [全新合成框架SOTA：强化学习当引擎，任务合成当燃料，蚂蚁港大联合出品](https://www.qbitai.com/2025/10/339049.html) — 量子位 · 2025-10-01 18:43
- [OpenAI突然发布Sora 2：好一个“AI版抖音”！](https://www.qbitai.com/2025/10/339008.html) — 量子位 · 2025-10-01 10:23
- [谁是2025年度最好的编程语言？](https://www.qbitai.com/2025/10/338993.html) — 量子位 · 2025-10-01 10:19
- [首次实现第一视角视频与人体动作同步生成！新框架攻克视角-动作对齐两大技术壁垒](https://www.qbitai.com/2025/10/338975.html) — 量子位 · 2025-10-01 09:54


## 论文 · arXiv

- [AccidentBench: Benchmarking Multimodal Understanding and Reasoning in   Vehicle Accidents and Beyond](http://arxiv.org/abs/2509.26636v1) — arXiv · MoE & Reasoning · 2025-10-01 01:59
- [Attention as a Compass: Efficient Exploration for Process-Supervised RL   in Reasoning Models](http://arxiv.org/abs/2509.26628v1) — arXiv · LLM core · 2025-10-01 01:58
- [Recursive Self-Aggregation Unlocks Deep Thinking in Large Language   Models](http://arxiv.org/abs/2509.26626v1) — arXiv · LLM core · 2025-10-01 01:58
- [Learning Generalizable Shape Completion with SIM(3) Equivariance](http://arxiv.org/abs/2509.26631v1) — arXiv · MoE & Reasoning · 2025-10-01 01:58
- [Learning to See Before Seeing: Demystifying LLM Visual Priors from   Language Pre-training](http://arxiv.org/abs/2509.26625v1) — arXiv · LLM core · 2025-10-01 01:57
- [MENLO: From Preferences to Proficiency -- Evaluating and Modeling   Native-like Quality Across 47 Languages](http://arxiv.org/abs/2509.26601v1) — arXiv · LLM core · 2025-10-01 01:48
- [Deconstructing Self-Bias in LLM-generated Translation Benchmarks](http://arxiv.org/abs/2509.26600v1) — arXiv · LLM core · 2025-10-01 01:48
- [Are Robust LLM Fingerprints Adversarially Robust?](http://arxiv.org/abs/2509.26598v1) — arXiv · LLM core · 2025-10-01 01:47
- [Generating Difficult-to-Translate Texts](http://arxiv.org/abs/2509.26592v1) — arXiv · LLM core · 2025-10-01 01:46
- [Clarification as Supervision: Reinforcement Learning for Vision-Language   Interfaces](http://arxiv.org/abs/2509.26594v1) — arXiv · MoE & Reasoning · 2025-10-01 01:46
- [Fairness Testing in Retrieval-Augmented Generation: How Small   Perturbations Reveal Bias in Small Language Models](http://arxiv.org/abs/2509.26584v1) — arXiv · LLM core · 2025-10-01 01:42
- [Linking Process to Outcome: Conditional Reward Modeling for LLM   Reasoning](http://arxiv.org/abs/2509.26578v1) — arXiv · LLM core · 2025-10-01 01:38
- [Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics   Research Benchmark](http://arxiv.org/abs/2509.26574v1) — arXiv · LLM core · 2025-10-01 01:34
- [Towards Reliable Benchmarking: A Contamination Free, Controllable   Evaluation Framework for Multi-step LLM Function Calling](http://arxiv.org/abs/2509.26553v1) — arXiv · MoE & Reasoning · 2025-10-01 01:21
- [Towards Verified Code Reasoning by LLMs](http://arxiv.org/abs/2509.26546v1) — arXiv · MoE & Reasoning · 2025-10-01 01:17

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
# LLM Daily Brief — 2026-02-11

- 生成时间：2026-02-11 21:18 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 官方 / 厂商 · 国外

- [Elevated errors on Opus 4.6](https://status.claude.com/incidents/3fsrljm3n64g) — Anthropic · Status · 2026-02-11 16:37


## 中文媒体

- [大晓机器人完成天使轮融资](https://www.jiqizhixin.com/articles/2026-02-11-12) — 机器之心 · 2026-02-11 18:36
- [OpenClaw：高强度使用两周，这个 AI 工具颠覆了我的工作流](https://sspai.com/post/106232) — 少数派 · 2026-02-11 17:47
- [决定了：过年攻略全都不过脑子，让AI去想](https://www.jiqizhixin.com/articles/2026-02-11-11) — 机器之心 · 2026-02-11 17:22
- [马斯克xAI再失联合创始人，12人创始团队已有6人离场](https://www.jiqizhixin.com/articles/2026-02-11-10) — 机器之心 · 2026-02-11 17:16
- [复刻、长语音、对话、指令、音效全覆盖！模思智能推出MOSS-TTS Family！](https://www.jiqizhixin.com/articles/2026-02-11-9) — 机器之心 · 2026-02-11 17:13
- [寻源南疆：我们在冰山上拍了一部「公路电影」](https://sspai.com/post/106299) — 少数派 · 2026-02-11 16:27
- [华为云大动作！马年春节前夕，码道开启万人公测](https://www.jiqizhixin.com/articles/2026-02-11-8) — 机器之心 · 2026-02-11 15:37
- [索尼 LinkBuds Clip 耳夹式开放真无线耳机体验 - TDS REVIEW](https://sspai.com/post/106175) — 少数派 · 2026-02-11 15:31
- [特斯拉腾讯首次合作，新老Model 3/Y车主爽到了](https://www.qbitai.com/2026/02/378503.html) — 量子位 · 2026-02-11 14:34
- [史上最长春节假期即将开启，千问APP联合飞猪推出“千问价”](https://www.qbitai.com/2026/02/378498.html) — 量子位 · 2026-02-11 14:02
- [马斯克xAI雪崩！24小时两联创离职，一月内连失三位华人创始人](https://www.qbitai.com/2026/02/378462.html) — 量子位 · 2026-02-11 13:37
- [网易有道发布中国版“OpenClaw”，推出全场景个人助理Agent“LobsterAI”](https://www.qbitai.com/2026/02/378453.html) — 量子位 · 2026-02-11 12:05
- [模型、框架、应用量产工作流，原力灵机三箭齐发，开启具身智能”原生时刻”](https://www.qbitai.com/2026/02/378450.html) — 量子位 · 2026-02-11 12:03
- [从一台修不好的 Walkman 开始：飞傲的复古产品「补票」之路](https://sspai.com/post/106146) — 少数派 · 2026-02-11 11:32


## 英文媒体 / Newsletter

- [[AINews] Qwen Image 2 and Seedance 2](https://www.latent.space/p/ainews-qwen-image-2-and-seedance) — Latent Space · 2026-02-11 13:19


## 论文 · arXiv

- [Biases in the Blind Spot: Detecting What LLMs Fail to Mention](https://arxiv.org/abs/2602.10117v1) — arXiv · LLM core · 2026-02-11 02:59
- [Step-resolved data attribution for looped transformers](https://arxiv.org/abs/2602.10097v1) — arXiv · MoE & Reasoning · 2026-02-11 02:57
- [Causality in Video Diffusers is Separable from Denoising](https://arxiv.org/abs/2602.10095v1) — arXiv · MoE & Reasoning · 2026-02-11 02:57
- [Quantum-Audit: Evaluating the Reasoning Limits of LLMs on Quantum Computing](https://arxiv.org/abs/2602.10092v1) — arXiv · LLM core · 2026-02-11 02:56
- [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090v1) — arXiv · LLM core · 2026-02-11 02:55
- [Anagent For Enhancing Scientific Table & Figure Analysis](https://arxiv.org/abs/2602.10081v1) — arXiv · MoE & Reasoning · 2026-02-11 02:46
- [CAPID: Context-Aware PII Detection for Question-Answering Systems](https://arxiv.org/abs/2602.10074v1) — arXiv · LLM core · 2026-02-11 02:41
- [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063v1) — arXiv · LLM core · 2026-02-11 02:31
- [Long Chain-of-Thought Compression via Fine-Grained Group Policy Optimization](https://arxiv.org/abs/2602.10048v1) — arXiv · LLM core · 2026-02-11 02:15
- [Fake-HR1: Rethinking reasoning of vision language model for synthetic image detection](https://arxiv.org/abs/2602.10042v1) — arXiv · LLM core · 2026-02-11 02:10
- [MEVER: Multi-Modal and Explainable Claim Verification with Graph-based Evidence Retrieval](https://arxiv.org/abs/2602.10023v1) — arXiv · MoE & Reasoning · 2026-02-11 01:44
- [Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference](https://arxiv.org/abs/2602.10021v1) — arXiv · LLM core · 2026-02-11 01:42
- [SCORE: Specificity, Context Utilization, Robustness, and Relevance for Reference-Free LLM Evaluation](https://arxiv.org/abs/2602.10017v1) — arXiv · LLM core · 2026-02-11 01:39
- [Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design](https://arxiv.org/abs/2602.10016v1) — arXiv · LLM core · 2026-02-11 01:37

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
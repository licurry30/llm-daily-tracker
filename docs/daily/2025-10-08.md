# LLM Daily Brief — 2025-10-08

- 生成时间：2025-10-08 20:45 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [直播预告：光轮智能 × NVIDIA带来Sim2Real关键突破](https://www.qbitai.com/2025/10/339901.html) — 量子位 · 2025-10-08 19:28
- [首个全自动AI科学家诞生！西湖大学最新成果：性能超越人类SOTA基线183.7%](https://www.qbitai.com/2025/10/339884.html) — 量子位 · 2025-10-08 19:24
- [AI 学习模式：让 ChatGPT 当导师，究竟是「邪修」破局还是暗藏陷阱？](https://sspai.com/post/102377) — 少数派 · 2025-10-08 14:13
- [30家Tokens吞金兽，每家烧光万亿Tokens！OpenAI最大客户名单曝光，多邻国上榜](https://www.qbitai.com/2025/10/339866.html) — 量子位 · 2025-10-08 12:37
- [另一位Yao Shunyu也跳槽了：与Anthropic价值观有根本分歧](https://www.qbitai.com/2025/10/339852.html) — 量子位 · 2025-10-08 12:29


## 论文 · arXiv

- [EgoNight: Towards Egocentric Vision Understanding at Night with a   Challenging Benchmark](http://arxiv.org/abs/2510.06218v1) — arXiv · LLM core · 2025-10-08 01:59
- [Stratified GRPO: Handling Structural Heterogeneity in Reinforcement   Learning of LLM Search Agents](http://arxiv.org/abs/2510.06214v1) — arXiv · LLM core · 2025-10-08 01:59
- [Training Dynamics Impact Post-Training Quantization Robustness](http://arxiv.org/abs/2510.06213v1) — arXiv · LLM core · 2025-10-08 01:59
- [TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular   Reasoning](http://arxiv.org/abs/2510.06217v1) — arXiv · MoE & Reasoning · 2025-10-08 01:59
- [Peeking inside the Black-Box: Reinforcement Learning for Explainable and   Accurate Relation Extraction](http://arxiv.org/abs/2510.06198v1) — arXiv · LLM core · 2025-10-08 01:53
- [On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond](http://arxiv.org/abs/2510.06190v1) — arXiv · LLM core · 2025-10-08 01:49
- [Barbarians at the Gate: How AI is Upending Systems Research](http://arxiv.org/abs/2510.06189v1) — arXiv · LLM core · 2025-10-08 01:49
- [Automated Program Repair of Uncompilable Student Code](http://arxiv.org/abs/2510.06187v1) — arXiv · LLM core · 2025-10-08 01:46
- [RECODE-H: A Benchmark for Research Code Development with Interactive   Human Feedback](http://arxiv.org/abs/2510.06186v1) — arXiv · LLM core · 2025-10-08 01:45
- [Mixing Mechanisms: How Language Models Retrieve Bound Entities   In-Context](http://arxiv.org/abs/2510.06182v1) — arXiv · MoE & Reasoning · 2025-10-08 01:44
- [VecInfer: Efficient LLM Inference with Low-Bit KV Cache via   Outlier-Suppressed Vector Quantization](http://arxiv.org/abs/2510.06175v1) — arXiv · LLM core · 2025-10-08 01:35
- [LLMs as Policy-Agnostic Teammates: A Case Study in Human Proxy Design   for Heterogeneous Agent Teams](http://arxiv.org/abs/2510.06151v1) — arXiv · LLM core · 2025-10-08 01:21
- [Discrete Diffusion Models with MLLMs for Unified Medical Multimodal   Generation](http://arxiv.org/abs/2510.06131v1) — arXiv · MoE & Reasoning · 2025-10-08 01:06
- [Influence Functions for Efficient Data Selection in Reasoning](http://arxiv.org/abs/2510.06108v1) — arXiv · MoE & Reasoning · 2025-10-08 00:40
- [Distributional Semantics Tracing: A Framework for Explaining   Hallucinations in Large Language Models](http://arxiv.org/abs/2510.06107v1) — arXiv · MoE & Reasoning · 2025-10-08 00:40
- [The Valley of Code Reasoning: Scaling Knowledge Distillation of Large   Language Models](http://arxiv.org/abs/2510.06101v1) — arXiv · MoE & Reasoning · 2025-10-08 00:32

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
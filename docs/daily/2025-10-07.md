# LLM Daily Brief — 2025-10-07

- 生成时间：2025-10-07 20:45 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [2025诺贝尔物理学奖颁给了谷歌量子计算机打造者](https://www.qbitai.com/2025/10/339842.html) — 量子位 · 2025-10-07 19:27
- [用 AI 帮我改善口吃：一段关于自我和解的旅程](https://sspai.com/post/102860) — 少数派 · 2025-10-07 15:00
- [ChatGPT内嵌App！OpenAI开发者日全览，Agent工具链+应用生态+模型API多箭齐发](https://www.qbitai.com/2025/10/339739.html) — 量子位 · 2025-10-07 12:50


## 论文 · arXiv

- [From Noisy Traces to Stable Gradients: Bias-Variance Optimized   Preference Optimization for Aligning Large Reasoning Models](http://arxiv.org/abs/2510.05095v1) — arXiv · MoE & Reasoning · 2025-10-07 01:58
- [Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for   Diffusion Large Language Models](http://arxiv.org/abs/2510.05090v1) — arXiv · LLM core · 2025-10-07 01:56
- [TeachLM: Post-Training LLMs for Education Using Authentic Learning Data](http://arxiv.org/abs/2510.05087v1) — arXiv · LLM core · 2025-10-07 01:55
- [Slm-mux: Orchestrating small language models for reasoning](http://arxiv.org/abs/2510.05077v1) — arXiv · MoE & Reasoning · 2025-10-07 01:49
- [SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior   Reasoning LLMs](http://arxiv.org/abs/2510.05069v1) — arXiv · LLM core · 2025-10-07 01:46
- [Boomerang Distillation Enables Zero-Shot Model Size Interpolation](http://arxiv.org/abs/2510.05064v1) — arXiv · LLM core · 2025-10-07 01:41
- [Staircase Streaming for Low-Latency Multi-Agent Inference](http://arxiv.org/abs/2510.05059v1) — arXiv · LLM core · 2025-10-07 01:37
- [ResCP: Reservoir Conformal Prediction for Time Series Forecasting](http://arxiv.org/abs/2510.05060v1) — arXiv · MoE & Reasoning · 2025-10-07 01:37
- [Modeling Student Learning with 3.8 Million Program Traces](http://arxiv.org/abs/2510.05056v1) — arXiv · MoE & Reasoning · 2025-10-07 01:37
- [Proactive defense against LLM Jailbreak](http://arxiv.org/abs/2510.05052v1) — arXiv · LLM core · 2025-10-07 01:32
- [COLE: a Comprehensive Benchmark for French Language Understanding   Evaluation](http://arxiv.org/abs/2510.05046v1) — arXiv · LLM core · 2025-10-07 01:26
- [Look-ahead Reasoning with a Learned Model in Imperfect Information Games](http://arxiv.org/abs/2510.05048v1) — arXiv · MoE & Reasoning · 2025-10-07 01:26
- [Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive   Experts](http://arxiv.org/abs/2510.05040v1) — arXiv · LLM core · 2025-10-07 01:16
- [A Set of Quebec-French Corpus of Regional Expressions and Terms](http://arxiv.org/abs/2510.05026v1) — arXiv · LLM core · 2025-10-07 01:04
- [Imperceptible Jailbreaking against Large Language Models](http://arxiv.org/abs/2510.05025v1) — arXiv · LLM core · 2025-10-07 01:03
- [Large Language Models Achieve Gold Medal Performance at International   Astronomy & Astrophysics Olympiad](http://arxiv.org/abs/2510.05016v1) — arXiv · MoE & Reasoning · 2025-10-07 00:58

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
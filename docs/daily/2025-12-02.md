# LLM Daily Brief — 2025-12-02

- 生成时间：2025-12-02 20:51 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [能讲“悄悄话”的智能助理，瑞声科技助力夸克AI眼镜S1开创 语音交互新范式](https://www.qbitai.com/2025/12/358264.html) — 量子位 · 2025-12-02 20:00
- [NeurIPS 2025｜CAKE：大模型驱动的贝叶斯优化新配方，让黑箱优化更智能、更高效](https://www.jiqizhixin.com/articles/2025-12-02-10) — 机器之心 · 2025-12-02 18:55
- [小猿学练机荣获2025 IDEA国际设计奖，开创学习平板品类新高度](https://www.qbitai.com/2025/12/358260.html) — 量子位 · 2025-12-02 18:40
- [唯一中国声音！智平方受邀亮相ITSA，为沙特Vision 2030注入中国具身力量](https://www.jiqizhixin.com/articles/2025-12-02-17) — 机器之心 · 2025-12-02 18:15
- [Runway Gen-4.5刷屏发布，把重量尘土和光影都做对了，网友：颠覆](https://www.qbitai.com/2025/12/358232.html) — 量子位 · 2025-12-02 17:56
- [社区速递 120 | 派友十月买了啥精编版、一周热评以及迷你摩卡壶](https://sspai.com/post/104235) — 少数派 · 2025-12-02 17:36
- [这下Altman急了，OpenAI紧急启动「红色警报」](https://www.jiqizhixin.com/articles/2025-12-02-16) — 机器之心 · 2025-12-02 17:32
- [迎接「万物皆可RAG」时代：最新综述展示50多种多模态组合的巨大待探索空间](https://www.jiqizhixin.com/articles/2025-12-02-15) — 机器之心 · 2025-12-02 17:29
- [宁德时代给9万+基层员工涨了薪！每月150元](https://www.qbitai.com/2025/12/358124.html) — 量子位 · 2025-12-02 17:11
- [商汤分拆了一家AI医疗公司，半年融资10亿，剑指“医疗世界模型”](https://www.qbitai.com/2025/12/358110.html) — 量子位 · 2025-12-02 16:52
- [从“数据融合”迈向“原生架构”：商汤发布 NEO 架构，重新定义多模态模型效能边界](https://www.jiqizhixin.com/articles/2025-12-02-14) — 机器之心 · 2025-12-02 16:25
- [被量化的心跳：HRV 是身体的晴雨表，还是制造焦虑的数字游戏？](https://sspai.com/post/104231) — 少数派 · 2025-12-02 15:00
- [Quote/0 新玩法：当「张大妈」遇上「打工人」，我们把职场黑话做成了贴纸](https://sspai.com/post/104126) — 少数派 · 2025-12-02 11:30


## 论文 · arXiv

- [Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling](https://arxiv.org/abs/2512.02010v1) — arXiv · LLM core · 2025-12-02 02:59
- [The Art of Scaling Test-Time Compute for Large Language Models](https://arxiv.org/abs/2512.02008v1) — arXiv · LLM core · 2025-12-02 02:59
- [Improved Mean Flows: On the Challenges of Fastforward Generative Models](https://arxiv.org/abs/2512.02012v1) — arXiv · MoE & Reasoning · 2025-12-02 02:59
- [AlignSAE: Concept-Aligned Sparse Autoencoders](https://arxiv.org/abs/2512.02004v1) — arXiv · LLM core · 2025-12-02 02:58
- [LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess](https://arxiv.org/abs/2512.01992v1) — arXiv · LLM core · 2025-12-02 02:51
- [Low-Rank Prehab: Preparing Neural Networks for SVD Compression](https://arxiv.org/abs/2512.01980v1) — arXiv · LLM core · 2025-12-02 02:37
- [Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback](https://arxiv.org/abs/2512.01979v1) — arXiv · LLM core · 2025-12-02 02:37
- [From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning](https://arxiv.org/abs/2512.01970v1) — arXiv · MoE & Reasoning · 2025-12-02 02:27
- [Learned-Rule-Augmented Large Language Model Evaluators](https://arxiv.org/abs/2512.01958v1) — arXiv · LLM core · 2025-12-02 02:08
- [KV Pareto: Systems-Level Optimization of KV Cache and Model Compression for Long Context Inference](https://arxiv.org/abs/2512.01953v1) — arXiv · LLM core · 2025-12-02 02:03
- [GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment](https://arxiv.org/abs/2512.01952v1) — arXiv · LLM core · 2025-12-02 02:03
- [How Far Are We from Genuinely Useful Deep Research Agents?](https://arxiv.org/abs/2512.01948v1) — arXiv · LLM core · 2025-12-02 01:58
- [Agentic Policy Optimization via Instruction-Policy Co-Evolution](https://arxiv.org/abs/2512.01945v1) — arXiv · MoE & Reasoning · 2025-12-02 01:56
- [Rectifying LLM Thought from Lens of Optimization](https://arxiv.org/abs/2512.01925v1) — arXiv · MoE & Reasoning · 2025-12-02 01:41
- [Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning](https://arxiv.org/abs/2512.01878v1) — arXiv · MoE & Reasoning · 2025-12-02 00:59

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
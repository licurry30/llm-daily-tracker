# LLM Daily Brief — 2025-12-24

- 生成时间：2025-12-24 20:50 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [谁还敢说谷歌掉队？2025年，它打了一场漂亮的翻身仗](https://www.jiqizhixin.com/articles/2025-12-24-10) — 机器之心 · 2025-12-24 18:03
- [北航提出代码大模型的 Scaling Laws：编程语言差异与多语言最优配比策略](https://www.jiqizhixin.com/articles/2025-12-24-9) — 机器之心 · 2025-12-24 17:56
- [DeepSeek官方点赞元宝，罕见现身互动](https://www.jiqizhixin.com/articles/2025-12-24-8) — 机器之心 · 2025-12-24 17:36
- [DeepSeek官方点赞元宝，罕见现身互动](https://www.qbitai.com/2025/12/365765.html) — 量子位 · 2025-12-24 17:33
- [号称「反重力」的谷歌 AI 编辑器，能原地起飞吗？](https://sspai.com/post/104769) — 少数派 · 2025-12-24 17:27
- [长城王牌产品线也要全面NOA了！供应商赛马，多阶方案并行](https://www.qbitai.com/2025/12/365751.html) — 量子位 · 2025-12-24 16:59
- [实测MiniMax M2.1之后，我们终于看懂了其招股书里的技术底气](https://www.jiqizhixin.com/articles/2025-12-24-7) — 机器之心 · 2025-12-24 16:22
- [直面VLA的「阿喀琉斯之踵」：TeleAI用「反探索」提升具身推理稳定性](https://www.jiqizhixin.com/articles/2025-12-24-6) — 机器之心 · 2025-12-24 16:13
- [敲响圣诞「叮叮当」，让这 9 部圣诞影片陪你迎接新年](https://sspai.com/post/85156) — 少数派 · 2025-12-24 15:17
- [关于价值的计算：少数派会员五周年的回顾与展望](https://sspai.com/post/104517) — 少数派 · 2025-12-24 15:06
- [国产AI4S创业头雁再获8亿投资！深势科技完成C轮，产品已服务300万科学家](https://www.qbitai.com/2025/12/365728.html) — 量子位 · 2025-12-24 14:59
- [Science打脸“赢在起跑线”！少年天才90%成年后止步顶尖水平之下](https://www.qbitai.com/2025/12/365710.html) — 量子位 · 2025-12-24 12:21
- [Quote/0版本更新：从「主动追踪」到「被动感知」，让信息融入日常](https://sspai.com/post/104809) — 少数派 · 2025-12-24 11:00


## 论文 · arXiv

- [LongVideoAgent: Multi-Agent Reasoning with Long Videos](https://arxiv.org/abs/2512.20618v1) — arXiv · LLM core · 2025-12-24 02:59
- [Making Large Language Models Efficient Dense Retrievers](https://arxiv.org/abs/2512.20612v1) — arXiv · LLM core · 2025-12-24 02:58
- [MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts](https://arxiv.org/abs/2512.20604v1) — arXiv · MoE & Reasoning · 2025-12-24 02:50
- [Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs](https://arxiv.org/abs/2512.20595v1) — arXiv · LLM core · 2025-12-24 02:43
- [Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent](https://arxiv.org/abs/2512.20586v1) — arXiv · LLM core · 2025-12-24 02:32
- [Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits](https://arxiv.org/abs/2512.20578v1) — arXiv · LLM core · 2025-12-24 02:21
- [Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs](https://arxiv.org/abs/2512.20573v1) — arXiv · LLM core · 2025-12-24 02:16
- [Distilling to Hybrid Attention Models via KL-Guided Layer Selection](https://arxiv.org/abs/2512.20569v1) — arXiv · LLM core · 2025-12-24 02:12
- [Benchmarking LLMs for Predictive Applications in the Intensive Care Units](https://arxiv.org/abs/2512.20520v1) — arXiv · LLM core · 2025-12-24 01:08
- [Step-DeepResearch Technical Report](https://arxiv.org/abs/2512.20491v1) — arXiv · LLM core · 2025-12-24 00:32
- [SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization](https://arxiv.org/abs/2512.20482v1) — arXiv · LLM core · 2025-12-24 00:18
- [Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale](https://arxiv.org/abs/2512.20469v1) — arXiv · MoE & Reasoning · 2025-12-24 00:04
- [BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples](https://arxiv.org/abs/2512.20403v1) — arXiv · MoE & Reasoning · 2025-12-23 22:46
- [Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems](https://arxiv.org/abs/2512.20387v1) — arXiv · MoE & Reasoning · 2025-12-23 22:22

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
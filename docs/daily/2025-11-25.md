# LLM Daily Brief — 2025-11-25

- 生成时间：2025-11-25 20:49 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 官方 / 厂商 · 国外

- [Elevated Error Rates on the API](https://status.claude.com/incidents/1y63m9yzpjn2) — Anthropic · Status · 2025-11-25 18:42


## 中文媒体

- [青年科学家数量创新高！35位新一期“新基石研究员”获资助](https://www.jiqizhixin.com/articles/2025-11-25-12) — 机器之心 · 2025-11-25 18:33
- [从推荐算法优化到AI4S、Pico和大模型，杨震原长文揭秘字节跳动的技术探索](https://www.jiqizhixin.com/articles/2025-11-25-11) — 机器之心 · 2025-11-25 18:03
- [哈工大深圳团队推出Uni-MoE-2.0-Omni：全模态理解、推理及生成新SOTA](https://www.jiqizhixin.com/articles/2025-11-25-10) — 机器之心 · 2025-11-25 17:57
- [社区速递 119 | 派友对智能眼镜的看法、一周热评以及新玩意](https://sspai.com/post/104066) — 少数派 · 2025-11-25 17:30
- [特朗普签署创世纪计划——指示科学机构拥抱人工智能](https://www.jiqizhixin.com/articles/2025-11-25-9) — 机器之心 · 2025-11-25 17:25
- [直播预告｜飞傲 DM15 R2R 便携蓝牙 CD 播放机 正式发售](https://sspai.com/post/104065) — 少数派 · 2025-11-25 16:00
- [用 Tasker 在桌面上随机回顾微信读书笔记](https://sspai.com/prime/story/wechat-read-annotations-widget-tasker) — 少数派 · 2025-11-25 15:42
- [Matrix 圆桌｜聊聊那些让你离不开的「平台独占」](https://sspai.com/post/104030) — 少数派 · 2025-11-25 15:00
- [学生3年投稿6次被拒，于是吴恩达亲手搓了个评审Agent](https://www.qbitai.com/2025/11/356247.html) — 量子位 · 2025-11-25 14:48
- [波士顿动力前CTO加盟DeepMind，Gemini要做机器人界的安卓](https://www.qbitai.com/2025/11/356219.html) — 量子位 · 2025-11-25 14:42
- [马斯克开始用Grok替代员工了！最惨部门裁员90%](https://www.qbitai.com/2025/11/356162.html) — 量子位 · 2025-11-25 14:24
- [Gemini 3，是谢尔盖・布林「骂」出来的？](https://www.jiqizhixin.com/articles/2025-11-25-8) — 机器之心 · 2025-11-25 12:59
- [二十五载聚智启新章，中国股权投资年度大会深圳将启](https://www.qbitai.com/2025/11/356152.html) — 量子位 · 2025-11-25 11:46
- [习惯养成 ABC：要如何克服内心的静摩擦力？](https://sspai.com/post/103458) — 少数派 · 2025-11-25 11:33
- [Nano Banana新玩法无限套娃！“GPT-5都不会处理这种级别的递归”](https://www.qbitai.com/2025/11/356060.html) — 量子位 · 2025-11-25 11:30


## 论文 · arXiv

- [Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering](https://arxiv.org/abs/2511.19427v1) — arXiv · LLM core · 2025-11-25 02:58
- [Flow Map Distillation Without Data](https://arxiv.org/abs/2511.19428v1) — arXiv · MoE & Reasoning · 2025-11-25 02:58
- [Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design](https://arxiv.org/abs/2511.19423v1) — arXiv · LLM core · 2025-11-25 02:57
- [SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning](https://arxiv.org/abs/2511.19422v1) — arXiv · LLM core · 2025-11-25 02:56
- [Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration](https://arxiv.org/abs/2511.19417v1) — arXiv · LLM core · 2025-11-25 02:55
- [Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens](https://arxiv.org/abs/2511.19418v1) — arXiv · MoE & Reasoning · 2025-11-25 02:55
- [Learning Robust Social Strategies with Large Language Models](https://arxiv.org/abs/2511.19405v1) — arXiv · LLM core · 2025-11-25 02:43
- [LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems](https://arxiv.org/abs/2511.19368v1) — arXiv · LLM core · 2025-11-25 02:03
- [Leveraging LLMs for reward function design in reinforcement learning control tasks](https://arxiv.org/abs/2511.19355v1) — arXiv · LLM core · 2025-11-25 01:55
- [Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric](https://arxiv.org/abs/2511.19350v1) — arXiv · LLM core · 2025-11-25 01:52
- [Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces](https://arxiv.org/abs/2511.19333v1) — arXiv · LLM core · 2025-11-25 01:26
- [Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval](https://arxiv.org/abs/2511.19325v1) — arXiv · LLM core · 2025-11-25 01:18
- [PRInTS: Reward Modeling for Long-Horizon Information Seeking](https://arxiv.org/abs/2511.19314v1) — arXiv · MoE & Reasoning · 2025-11-25 01:09
- [Psychometric Tests for AI Agents and Their Moduli Space](https://arxiv.org/abs/2511.19262v1) — arXiv · MoE & Reasoning · 2025-11-25 00:15
- [A Nutrition Multimodal Photoplethysmography Language Model](https://arxiv.org/abs/2511.19260v1) — arXiv · MoE & Reasoning · 2025-11-25 00:12
- [Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering](https://arxiv.org/abs/2511.19220v1) — arXiv · MoE & Reasoning · 2025-11-24 23:26

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
# LLM Daily Brief — 2025-12-11

- 生成时间：2025-12-11 20:53 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [大模型的第一性原理：（一）统计物理篇](https://www.jiqizhixin.com/articles/2025-12-11-11) — 机器之心 · 2025-12-11 18:34
- [张亚勤院士：基础大模型最终不超过10个，十年后机器人比人多 | MEET2026](https://www.qbitai.com/2025/12/360373.html) — 量子位 · 2025-12-11 18:34
- [何恺明NeurIPS 2025演讲盘点：视觉目标检测三十年](https://www.jiqizhixin.com/articles/2025-12-11-10) — 机器之心 · 2025-12-11 18:20
- [效率提升25%，灵巧操作数采困境被「臂-手共享自主框架」解决](https://www.jiqizhixin.com/articles/2025-12-11-9) — 机器之心 · 2025-12-11 18:11
- [朱啸虎投资，Refly.AI黄巍：n8n、扣子太难用，Vibe Workflow才是更大众的解决方案](http://www.geekpark.net/news/357942) — 极客公园 · 2025-12-11 17:55
- [马斯克霸气回怼Waymo：连对抗特斯拉的机会都没有](https://www.qbitai.com/2025/12/360255.html) — 量子位 · 2025-12-11 16:15
- [钉钉又发新版本！把 AI 搬进每一次对话和会议](https://www.qbitai.com/2025/12/360243.html) — 量子位 · 2025-12-11 15:33
- [MEET2026挤爆了，AI圈今年最该听的20+场演讲&对谈都在这](https://www.qbitai.com/2025/12/360136.html) — 量子位 · 2025-12-11 15:16
- [买哪款、怎么买：双十二 iPhone 选购指南](https://sspai.com/post/104349) — 少数派 · 2025-12-11 15:02
- [BrainOmni：首个统一脑电磁基础模型，实现跨设备、跨模态的通用脑信号表征](https://www.jiqizhixin.com/articles/2025-12-11-8) — 机器之心 · 2025-12-11 14:52
- [把数据中心塞进办公桌，让智能开发快N倍 ⚡](https://www.jiqizhixin.com/articles/2025-12-11-7) — 机器之心 · 2025-12-11 14:29
- [2026 硬件觉醒：AI 硬件迎来「安卓时刻」](http://www.geekpark.net/news/357920) — 极客公园 · 2025-12-11 14:19
- [慧思开物全局调度，北京人形推出全国首个全自主无人化导览解决方案](https://www.qbitai.com/2025/12/360124.html) — 量子位 · 2025-12-11 13:49
- [记一次拥抱开源地图的尝试：让 Organic Maps 在国内可用](https://sspai.com/post/104395) — 少数派 · 2025-12-11 11:35
- [XREAL 徐驰：智能眼镜，拉开了「Agent as Hardware」的新时代](http://www.geekpark.net/news/357904) — 极客公园 · 2025-12-11 10:50
- [Teeni.AI 袁琳：10 后与 AI 的共生关系，将如空气般自然](http://www.geekpark.net/news/357903) — 极客公园 · 2025-12-11 10:42
- [中国 AI 硬件团队，在 Kickstarter 上找到「第三条路」](http://www.geekpark.net/news/357902) — 极客公园 · 2025-12-11 10:38


## 论文 · arXiv

- [Efficient Continual Learning in Neural Machine Translation: A Low-Rank Adaptation Approach](https://arxiv.org/abs/2512.09910v1) — arXiv · MoE & Reasoning · 2025-12-11 02:37
- [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897v1) — arXiv · LLM core · 2025-12-11 02:26
- [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886v1) — arXiv · MoE & Reasoning · 2025-12-11 02:15
- [FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning](https://arxiv.org/abs/2512.09872v1) — arXiv · LLM core · 2025-12-11 01:58
- [MedForget: Hierarchy-Aware Multimodal Unlearning Testbed for Medical AI](https://arxiv.org/abs/2512.09867v1) — arXiv · LLM core · 2025-12-11 01:55
- [Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement](https://arxiv.org/abs/2512.09854v1) — arXiv · LLM core · 2025-12-11 01:36
- [ChronusOmni: Improving Time Awareness of Omni Large Language Models](https://arxiv.org/abs/2512.09841v1) — arXiv · LLM core · 2025-12-11 01:22
- [Predicting the Containment Time of California Wildfires Using Machine Learning](https://arxiv.org/abs/2512.09835v1) — arXiv · MoE & Reasoning · 2025-12-11 01:14
- [LLMs in Interpreting Legal Documents](https://arxiv.org/abs/2512.09830v1) — arXiv · LLM core · 2025-12-11 01:09
- [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829v1) — arXiv · LLM core · 2025-12-11 01:07
- [CHEM: Estimating and Understanding Hallucinations in Deep Learning for Image Processing](https://arxiv.org/abs/2512.09806v1) — arXiv · MoE & Reasoning · 2025-12-11 00:20
- [M3Net: A Multi-Metric Mixture of Experts Network Digital Twin with Graph Neural Networks](https://arxiv.org/abs/2512.09797v1) — arXiv · MoE & Reasoning · 2025-12-11 00:12
- [DeepSeek's WEIRD Behavior: The cultural alignment of Large Language Models and the effects of prompt language and cultural prompting](https://arxiv.org/abs/2512.09772v1) — arXiv · LLM core · 2025-12-10 23:54
- [Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs](https://arxiv.org/abs/2512.09742v1) — arXiv · LLM core · 2025-12-10 23:21
- [Interpreto: An Explainability Library for Transformers](https://arxiv.org/abs/2512.09730v1) — arXiv · LLM core · 2025-12-10 23:12
- [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706v1) — arXiv · MoE & Reasoning · 2025-12-10 22:52

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
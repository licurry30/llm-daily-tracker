# LLM Daily Brief — 2025-12-04

- 生成时间：2025-12-04 20:52 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 中文媒体

- [中国AI计算开放架构创新风向标：HAIC2025重磅启幕](https://www.qbitai.com/2025/12/359022.html) — 量子位 · 2025-12-04 18:40
- [Sora APP 30天留存率：1%](https://www.qbitai.com/2025/12/358665.html) — 量子位 · 2025-12-04 18:37
- [免费版Banana2来了，Vidu推出Q2生图全家桶，限时无限免费](https://www.jiqizhixin.com/articles/2025-12-04-11) — 机器之心 · 2025-12-04 18:11
- [嘉宾全阵容揭晓！张亚勤孙茂松，百度小米商汤谷歌都要来MEET2026](https://www.qbitai.com/2025/12/358867.html) — 量子位 · 2025-12-04 18:09
- [下周三！量子位的这件大事就要来了｜MEET2026](https://www.qbitai.com/2025/12/358715.html) — 量子位 · 2025-12-04 17:45
- [抢到票的必读：创新大会 2026 超全攻略！](https://www.qbitai.com/2025/12/358683.html) — 量子位 · 2025-12-04 17:25
- [新玩意 229｜少数派的编辑们最近买了啥？](https://sspai.com/post/104311) — 少数派 · 2025-12-04 17:23
- [DeepSeek-V3.2巨「吃」Token，竟然是被GRPO背刺了](https://www.jiqizhixin.com/articles/2025-12-04-10) — 机器之心 · 2025-12-04 16:32
- [碾压π0.5，复旦团队首创「世界模型+具身训练+强化学习」闭环框架](https://www.jiqizhixin.com/articles/2025-12-04-9) — 机器之心 · 2025-12-04 16:28
- [四年砸下10亿，万有引力用三款专用芯片，证明MR还没死](http://www.geekpark.net/news/357617) — 极客公园 · 2025-12-04 16:28
- [抢到票的必读：创新大会 2026 超全攻略！](http://www.geekpark.net/news/357613) — 极客公园 · 2025-12-04 16:01
- [深入 iPhone 17 Pro：把 ProRes RAW 和 Open Gate 一次讲清楚](https://sspai.com/post/104213) — 少数派 · 2025-12-04 14:59
- [刚刚，云计算一哥出手，大家AI Agent自由了](https://www.jiqizhixin.com/articles/2025-12-04-8) — 机器之心 · 2025-12-04 14:38
- [从MiniMax到DeepSeek：为何头部大模型都在押注「交错思维」？](https://www.jiqizhixin.com/articles/2025-12-04-7) — 机器之心 · 2025-12-04 14:30
- [十年之后再出发，Apple 北京荟聚抢先看](https://sspai.com/post/104301) — 少数派 · 2025-12-04 14:00
- [冷冬将至，你可能需要的取暖秘笈](https://sspai.com/post/63395) — 少数派 · 2025-12-04 11:34


## 研究机构 / 开源社区

- [We Got Claude to Fine-Tune an Open Source LLM](https://huggingface.co/blog/hf-skills-training) — Hugging Face Blog · 2025-12-04 08:00


## 论文 · arXiv

- [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072v1) — arXiv · MoE & Reasoning · 2025-12-04 02:54
- [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062v1) — arXiv · LLM core · 2025-12-04 02:46
- [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044v1) — arXiv · LLM core · 2025-12-04 02:32
- [Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study](https://arxiv.org/abs/2512.04031v1) — arXiv · LLM core · 2025-12-04 02:13
- [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013v1) — arXiv · LLM core · 2025-12-04 01:49
- [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994v1) — arXiv · LLM core · 2025-12-04 01:23
- [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976v1) — arXiv · LLM core · 2025-12-04 01:06
- [Sponsored Questions and How to Auction Them](https://arxiv.org/abs/2512.03975v1) — arXiv · LLM core · 2025-12-04 01:06
- [Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning](https://arxiv.org/abs/2512.03973v1) — arXiv · MoE & Reasoning · 2025-12-04 01:05
- [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967v1) — arXiv · MoE & Reasoning · 2025-12-04 00:58
- [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955v1) — arXiv · LLM core · 2025-12-04 00:49
- [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943v1) — arXiv · LLM core · 2025-12-04 00:38
- [Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties](https://arxiv.org/abs/2512.03931v1) — arXiv · MoE & Reasoning · 2025-12-04 00:29
- [A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models](https://arxiv.org/abs/2512.03915v1) — arXiv · MoE & Reasoning · 2025-12-04 00:00
- [Hierarchical Vision Language Action Model Using Success and Failure Demonstrations](https://arxiv.org/abs/2512.03913v1) — arXiv · MoE & Reasoning · 2025-12-03 23:58
- [A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)](https://arxiv.org/abs/2512.03887v1) — arXiv · LLM core · 2025-12-03 23:37
- [Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models](https://arxiv.org/abs/2512.03882v1) — arXiv · MoE & Reasoning · 2025-12-03 23:34
- [OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance](https://arxiv.org/abs/2512.03874v1) — arXiv · MoE & Reasoning · 2025-12-03 23:28
- [PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation](https://arxiv.org/abs/2512.03848v1) — arXiv · MoE & Reasoning · 2025-12-03 22:49

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
# LLM Daily Brief — 2025-12-12

- 生成时间：2025-12-12 20:50 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 官方 / 厂商 · 国外

- [Unable to start chats on claude.ai](https://status.claude.com/incidents/h140lstlzbw7) — Anthropic · Status · 2025-12-12 16:00


## 中文媒体

- [港大开源ViMax火了，实现AI自编自导自演](https://www.jiqizhixin.com/articles/2025-12-12-10) — 机器之心 · 2025-12-12 18:16
- [本周看什么 | 最近值得一看的 10 部作品](https://sspai.com/post/104560) — 少数派 · 2025-12-12 18:00
- [提示词一响，烂片登场，OpenAI谈下200+迪士尼顶级IP出场费](https://www.jiqizhixin.com/articles/2025-12-12-9) — 机器之心 · 2025-12-12 17:54
- [深聊豆包手机：该关注这场「技术核试验」的什么？](http://www.geekpark.net/news/357996) — 极客公园 · 2025-12-12 17:34
- [谷歌智能体发力：增强版Gemini Deep Research和专属API都来了](https://www.qbitai.com/2025/12/360539.html) — 量子位 · 2025-12-12 15:48
- [中国机器人比赛应急救援，美国网友Reddit破防：我们还在给机器狗化妆拍段子](https://www.qbitai.com/2025/12/360542.html) — 量子位 · 2025-12-12 15:28
- [当运动相机不运动：聊一台正方形画幅的超广角定焦相机](https://sspai.com/post/104390) — 少数派 · 2025-12-12 15:10
- [GPT-5.2果然反超谷歌Gemini 3 Pro！北大数院校友核心贡献](https://www.qbitai.com/2025/12/360439.html) — 量子位 · 2025-12-12 14:39
- [ToC智能体火得快，但更大的价值在企业丨中关村科金@MEET2026](https://www.qbitai.com/2025/12/360476.html) — 量子位 · 2025-12-12 14:36
- [AI 驱动的科学系统分析框架：SciSciGPT 打开科学研究的新工作方式](https://www.jiqizhixin.com/articles/2025-12-12-8) — 机器之心 · 2025-12-12 14:10
- [10亿美元OpenAI股权兑换迪士尼版权！米老鼠救Sora来了](https://www.qbitai.com/2025/12/360465.html) — 量子位 · 2025-12-12 13:56
- [测测任永亮：为什么一家泛心理公司，要造个「有身体」的机器人？](http://www.geekpark.net/news/357971) — 极客公园 · 2025-12-12 13:32
- [里程碑时刻！首个100B扩散语言模型来了，技术报告揭秘背后细节](https://www.jiqizhixin.com/articles/2025-12-12-7) — 机器之心 · 2025-12-12 13:16
- [Runway深夜炸场：一口气发布5大更新，首个通用世界模型来了](https://www.jiqizhixin.com/articles/2025-12-12-6) — 机器之心 · 2025-12-12 13:08
- [我看 MiniMax 闫俊杰：「心舟」已过万重山](http://www.geekpark.net/news/357970) — 极客公园 · 2025-12-12 12:41
- [语核科技翟星吉：离钱最近的 Agent，才是 AI ToB 的唯一出路](http://www.geekpark.net/news/357968) — 极客公园 · 2025-12-12 12:03
- [App+1 | 好内容、零门槛：给外语播客的「沉浸式翻译」](https://sspai.com/post/104019) — 少数派 · 2025-12-12 11:35


## 论文 · arXiv

- [Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949v1) — arXiv · MoE & Reasoning · 2025-12-12 02:59
- [Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941v1) — arXiv · MoE & Reasoning · 2025-12-12 02:59
- [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931v1) — arXiv · LLM core · 2025-12-12 02:57
- [BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models](https://arxiv.org/abs/2512.10932v1) — arXiv · MoE & Reasoning · 2025-12-12 02:57
- [Decoupled Q-Chunking](https://arxiv.org/abs/2512.10926v1) — arXiv · MoE & Reasoning · 2025-12-12 02:52
- [SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale](https://arxiv.org/abs/2512.10922v1) — arXiv · LLM core · 2025-12-12 02:47
- [CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences](https://arxiv.org/abs/2512.10918v1) — arXiv · LLM core · 2025-12-12 02:44
- [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903v1) — arXiv · LLM core · 2025-12-12 02:32
- [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895v1) — arXiv · LLM core · 2025-12-12 02:23
- [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882v1) — arXiv · LLM core · 2025-12-12 02:11
- [MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence](https://arxiv.org/abs/2512.10863v1) — arXiv · MoE & Reasoning · 2025-12-12 01:57
- [Scaling Behavior of Discrete Diffusion Language Models](https://arxiv.org/abs/2512.10858v1) — arXiv · LLM core · 2025-12-12 01:54
- [Quantum Approaches to Urban Logistics: From Core QAOA to Clustered Scalability](https://arxiv.org/abs/2512.10813v1) — arXiv · MoE & Reasoning · 2025-12-12 01:00
- [Interpretable and Steerable Concept Bottleneck Sparse Autoencoders](https://arxiv.org/abs/2512.10805v1) — arXiv · LLM core · 2025-12-12 00:48
- [LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification](https://arxiv.org/abs/2512.10793v1) — arXiv · LLM core · 2025-12-12 00:39
- [What matters for Representation Alignment: Global Information or Spatial Structure?](https://arxiv.org/abs/2512.10794v1) — arXiv · MoE & Reasoning · 2025-12-12 00:39
- [The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality](https://arxiv.org/abs/2512.10791v1) — arXiv · LLM core · 2025-12-12 00:35
- [Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting](https://arxiv.org/abs/2512.10780v1) — arXiv · MoE & Reasoning · 2025-12-12 00:15

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。
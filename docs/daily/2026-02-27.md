# LLM Daily Brief — 2026-02-27

- 生成时间：2026-02-27 10:25 (Asia/Shanghai)
- 抓取窗口：24h · 源数：14


## 官方 / 厂商 · 国外

- [Claude Code showing "JSON Parse error: Unexpected EOF" and writing excessive files on Windows](https://status.claude.com/incidents/3kjy2zn2w2bj) — Anthropic · Status · 2026-02-27 07:07
- [Outage in usage reporting](https://status.claude.com/incidents/9s03yn69ky6m) — Anthropic · Status · 2026-02-27 06:10
- [Now Live: The World’s Most Powerful AI Factory for Pharmaceutical Discovery and Development](https://blogs.nvidia.com/blog/lilly-ai-factory-live/) — NVIDIA Technical Blog · 2026-02-27 03:00
- [Learnings from COBOL modernization in the real world](https://aws.amazon.com/blogs/machine-learning/learnings-from-cobol-modernization-in-the-real-world/) — AWS Machine Learning · Blog · 2026-02-27 02:16
- [Reinforcement fine-tuning for Amazon Nova: Teaching AI through feedback](https://aws.amazon.com/blogs/machine-learning/reinforcement-fine-tuning-for-amazon-nova-teaching-ai-through-feedback/) — AWS Machine Learning · Blog · 2026-02-27 01:48
- [Large model inference container – latest capabilities and performance enhancements](https://aws.amazon.com/blogs/machine-learning/large-model-inference-container-latest-capabilities-and-performance-enhancements/) — AWS Machine Learning · Blog · 2026-02-27 01:45
- [Issue with some ChatGPT Apps](https://status.openai.com//incidents/01KJD45ZHJHG8XM53V20JKKYNV) — OpenAI · Status · 2026-02-26 23:57
- [Horror Awakens in the Cloud: GeForce NOW Unleashes Capcom’s ‘Resident Evil Requiem’](https://blogs.nvidia.com/blog/geforce-now-thursday-resident-evil-requiem/) — NVIDIA Technical Blog · 2026-02-26 22:00


## 中文媒体

- [派早报：Apple 确认将于三月发布多款新品等](https://sspai.com/post/106637) — 少数派 · 2026-02-27 08:38


## 英文媒体 / Newsletter

- [[LIVE] Anthropic Distillation & How Models Cheat (SWE-Bench Dead) | Nathan Lambert & Sebastian Raschka](https://www.latent.space/p/paid-anthropic-distillation-and-how) — Latent Space · 2026-02-27 04:39


## 研究机构 / 开源社区

- [CORPGEN advances AI agents for real work](https://www.microsoft.com/en-us/research/blog/corpgen-advances-ai-agents-for-real-work/) — Microsoft Research · 2026-02-27 01:06


## 论文 · arXiv

- [Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems](https://arxiv.org/abs/2602.23266v1) — arXiv · LLM core · 2026-02-27 01:39
- [Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving](https://arxiv.org/abs/2602.23259v1) — arXiv · MoE & Reasoning · 2026-02-27 01:32
- [AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning](https://arxiv.org/abs/2602.23258v1) — arXiv · MoE & Reasoning · 2026-02-27 01:31
- [Mitigating Legibility Tax with Decoupled Prover-Verifier Games](https://arxiv.org/abs/2602.23248v1) — arXiv · LLM core · 2026-02-27 01:25
- [Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive](https://arxiv.org/abs/2602.23239v1) — arXiv · LLM core · 2026-02-27 01:16
- [Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments](https://arxiv.org/abs/2602.23234v1) — arXiv · LLM core · 2026-02-27 01:11
- [MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction](https://arxiv.org/abs/2602.23228v1) — arXiv · MoE & Reasoning · 2026-02-27 01:08
- [Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?](https://arxiv.org/abs/2602.23225v1) — arXiv · MoE & Reasoning · 2026-02-27 01:04
- [InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models](https://arxiv.org/abs/2602.23200v1) — arXiv · LLM core · 2026-02-27 00:50
- [SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation](https://arxiv.org/abs/2602.23199v1) — arXiv · LLM core · 2026-02-27 00:50
- [Fine-Tuning Without Forgetting In-Context Learning: A Theoretical Analysis of Linear Attention Models](https://arxiv.org/abs/2602.23197v1) — arXiv · LLM core · 2026-02-27 00:49
- [ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering](https://arxiv.org/abs/2602.23193v1) — arXiv · LLM core · 2026-02-27 00:45
- [MTRAG-UN: A Benchmark for Open Challenges in Multi-Turn RAG Conversations](https://arxiv.org/abs/2602.23184v1) — arXiv · LLM core · 2026-02-27 00:41
- [A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring](https://arxiv.org/abs/2602.23163v1) — arXiv · LLM core · 2026-02-27 00:27
- [PATRA: Pattern-Aware Alignment and Balanced Reasoning for Time Series Question Answering](https://arxiv.org/abs/2602.23161v1) — arXiv · MoE & Reasoning · 2026-02-27 00:20
- [Benchmarking Temporal Web3 Intelligence: Lessons from the FinSurvival 2025 Challenge](https://arxiv.org/abs/2602.23159v1) — arXiv · MoE & Reasoning · 2026-02-27 00:19

---
数据源与分组在 config.yaml → sections / feeds 中可自定义。